import os, json, re, hashlib, uuid
from pathlib import Path
from datetime import datetime
from flask import Flask, render_template, request, send_from_directory, flash, redirect, url_for, session
from werkzeug.utils import secure_filename
import pandas as pd
import numpy as np

from preprocess_of_data import run_preprocess
# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù…Ù† model.py (ØªØ¯Ø±ÙŠØ¨ + Ø­ÙØ¸) Ùˆ (ØªÙ†Ø¨Ø¤ ÙÙ‚Ø·)
from model import run_full_pipeline, forecast_only, train_and_save_models

ALLOWED_EXT = {"xlsx", "xls"}
BASE_DIR = Path(__file__).resolve().parent
RUNS_DIR = BASE_DIR / "runs"
UPLOADS_DIR = RUNS_DIR / "_uploads"

app = Flask(__name__)
app.secret_key = "change-me-please"
app.config["MAX_CONTENT_LENGTH"] = 100 * 1024 * 1024
RUNS_DIR.mkdir(exist_ok=True, parents=True)
UPLOADS_DIR.mkdir(exist_ok=True, parents=True)

# ------------------- Helpers -------------------
def allowed_file(filename: str) -> bool:
    return "." in filename and filename.rsplit(".", 1)[1].lower() in ALLOWED_EXT

def canonical_name(name: str) -> str:
    name = (name or "").strip()
    name = re.sub(r"\s+", "-", name)
    name = re.sub(r"[^A-Za-z0-9\-_]+", "", name)
    return name or "server"

def server_dir_path(server_name: str) -> Path:
    return RUNS_DIR / canonical_name(server_name)

def server_dir(server_name: str) -> Path:
    d = server_dir_path(server_name)
    d.mkdir(parents=True, exist_ok=True)
    return d

def file_md5(p: Path) -> str:
    import hashlib
    h = hashlib.md5()
    with open(p, "rb") as fh:
        for chunk in iter(lambda: fh.read(8192), b""):
            h.update(chunk)
    return h.hexdigest()

@app.after_request
def no_cache(resp):
    resp.headers["Cache-Control"] = "no-store"
    return resp
# ------------------------------------------------

# -------------------- Ø§Ù„ØµÙØ­Ø§Øª --------------------
@app.route("/", methods=["GET"])
def index():
    return render_template("index.html", prepared=False, server_name=None)

@app.route("/multi", methods=["GET"])
def multi_page():
    return render_template("multi.html", server_list=None)

# -------------------- Ø³ÙŠØ±ÙØ± ÙˆØ§Ø­Ø¯ --------------------
@app.post("/prepare")
def prepare():
    if "excel_file" not in request.files:
        flash("Ù„Ù… ÙŠØªÙ… Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³Ù„.", "error")
        return redirect(url_for("index"))
    
    up = request.files["excel_file"]
    server_name = (request.form.get("server_name") or "").strip()
    if not server_name:
        flash("Ø±Ø¬Ø§Ø¡Ù‹ Ø£Ø¯Ø®Ù„ÙŠ Ø§Ø³Ù… Ø§Ù„Ø³ÙŠØ±ÙØ±.", "error")
        return redirect(url_for("index"))
    if up.filename == "" or not allowed_file(up.filename):
        flash("Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³Ù„ ØºÙŠØ± ØµØ§Ù„Ø­.", "error")
        return redirect(url_for("index"))

    work = server_dir(server_name)
    excel_path = work / "DataOfServer.xlsx"

    # ğŸ”¹ ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ù…Ø­ÙÙˆØ¸Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹
    model_data_pkl = work / "model_DATA.np"
    model_log_pkl  = work / "model_LOG.np"
    if model_data_pkl.exists() and model_log_pkl.exists():
    
     return render_template(
        "index.html",
        prepared=True,
        server_name=server_name,
        already_trained=True  
    )


    # ğŸ”¹ Ø¥Ø°Ø§ Ù…Ø§ ÙÙŠÙ‡ Ù…ÙˆØ¯ÙŠÙ„Ø§ØªØŒ Ù†ÙƒÙ…Ù„ ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    up.save(str(excel_path))
    if not excel_path.exists():
        flash("ÙØ´Ù„ Ø­ÙØ¸ Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³Ù„. Ø£Ø¹ÙŠØ¯ÙŠ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©.", "error")
        return redirect(url_for("index"))

    # ØªÙ†Ø¸ÙŠÙ Ù…Ø®Ù„ÙØ§Øª Ù‚Ø¯ÙŠÙ…Ø© Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø³ÙŠØ±ÙØ± ÙÙ‚Ø· (Ù†ÙØ¨Ù‚ÙŠ Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§Ù„Ø¨Ø§Ø±Ø§Ù…ÙŠØªØ±Ø² Ø¥Ù† ÙˆØ¬Ø¯Øª)
    for p in work.glob("*.csv"):
        try:
            p.unlink()
        except:
            pass
    for p in work.glob("*.json"):
        if p.name not in ("best_params_DATA.json", "best_params_LOG.json"):
            try:
                p.unlink()
            except:
                pass

    meta = {"server": canonical_name(server_name), "excel_md5": file_md5(excel_path)}
    (work / "meta.json").write_text(json.dumps(meta, ensure_ascii=False), encoding="utf-8")

    try:
        _data_csv, _log_csv = run_preprocess(str(excel_path), server_name, out_dir=str(work))
        flash("ØªÙ… ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­. ÙŠÙ…ÙƒÙ†Ùƒ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø«Ù… Ø§Ø®ØªÙŠØ§Ø± Ù…Ø¯Ø© Ø§Ù„ØªÙ†Ø¨Ø¤.", "success")
        return render_template("index.html", prepared=True, server_name=server_name)
    except Exception as e:
        flash(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ø¶ÙŠØ±: {e}", "error")
        return redirect(url_for("index"))


@app.post("/run")
def run():
    """ÙŠØ¯Ø±Ø¨ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© ÙˆÙŠØ­ÙØ¸Ù‡Ø§ ÙÙ‚Ø· (Ø¨Ø¯ÙˆÙ† ØªÙˆÙ„ÙŠØ¯ ØªÙ†Ø¨Ø¤)."""
    server_name = (request.form.get("server_name") or "").strip()
    if not server_name:
        flash("Ø±Ø¬Ø§Ø¡Ù‹ Ø£Ø¯Ø®Ù„ÙŠ Ø§Ø³Ù… Ø§Ù„Ø³ÙŠØ±ÙØ±.", "error"); return redirect(url_for("index"))

    work = server_dir(server_name)
    meta_path = work / "meta.json"
    if not meta_path.exists():
        flash("ÙŠØ¬Ø¨ ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆÙ„Ø§Ù‹.", "error")
        return redirect(url_for("index"))

    data_csv = work / "data_preprocessed.csv"
    log_csv  = work / "log_preprocessed.csv"
    if not data_csv.exists() or not log_csv.exists():
        flash("ÙŠØ¬Ø¨ ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆÙ„Ø§Ù‹.", "error")
        return redirect(url_for("index"))

    try:
        # ØªØ¯Ø±ÙŠØ¨ ÙˆØ­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª
        _ = train_and_save_models(
            data_csv=str(data_csv),
            log_csv=str(log_csv),
            params_data=str(BASE_DIR / "best_params_DATA.json"),
            params_log=str(BASE_DIR / "best_params_LOG.json"),
            out_dir=str(work)
        )
        flash("ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆØ¯Ù„ ÙˆØ­ÙØ¸Ù‡. Ø§Ø®ØªØ§Ø±ÙŠ Ù…Ø¯Ø© Ø§Ù„ØªÙ†Ø¨Ø¤ ÙˆØ´ØºÙ‘Ù„ÙŠ /forecast.", "success")
        return render_template("index.html", prepared=True, server_name=server_name)
    except Exception as e:
        flash(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {e}", "error")
        return redirect(url_for("index"))

@app.post("/forecast")
def forecast():
    """ÙŠÙˆÙ„Ù‘Ø¯ Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙ†Ø¨Ø¤ Ù…Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø© Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©."""
    server_name = (request.form.get("server_name") or "").strip()
    months = int(request.form.get("months") or 6)

    work = server_dir(server_name)
    meta_path = work / "meta.json"
    if not meta_path.exists():
        flash("ÙŠØ¬Ø¨ Ø¥Ø¹Ø§Ø¯Ø© ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù‡Ø°Ø§ Ø§Ù„Ø³ÙŠØ±ÙØ± Ø£ÙˆÙ„Ø§Ù‹.", "error")
        return redirect(url_for("index"))

    data_csv = work / "data_preprocessed.csv"
    log_csv  = work / "log_preprocessed.csv"
    if not data_csv.exists() or not log_csv.exists():
        flash("ÙŠØ¬Ø¨ ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆÙ„Ø§Ù‹.", "error")
        return redirect(url_for("index"))

    model_data_path = work / "model_DATA.np"
    model_log_path  = work / "model_LOG.np"
    if not model_data_path.exists() or not model_log_path.exists():
        flash("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ù…Ø­ÙÙˆØ¸Ø© Ø¨Ø¹Ø¯. Ù‚ÙˆÙ…ÙŠ Ø¨ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø£ÙˆÙ„Ø§Ù‹.", "error")
        return redirect(url_for("index"))

    try:
        # ØªÙ†Ø¨Ø¤ ÙÙ‚Ø· Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©
        _ = forecast_only(str(model_data_path), str(data_csv), "DATA", months, out_dir=str(work))
        _ = forecast_only(str(model_log_path),  str(log_csv),  "LOG",  months, out_dir=str(work))
        return _render_results_page(work, server_name, months)
    except Exception as e:
        flash(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙ†Ø¨Ø¤: {e}", "error")
        return redirect(url_for("index"))

@app.post("/view")
def view():
    """Ø§Ø³ØªØ¹Ø±Ø§Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ù„Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©. Ø¥Ù† Ù„Ù… ÙŠÙˆØ¬Ø¯ Ù…Ù„Ù Ù„Ù„Ù…Ø¯Ø© ÙˆÙ„ÙƒÙ† ÙŠÙˆØ¬Ø¯ Ù…ÙˆØ¯ÙŠÙ„ Ù…Ø­ÙÙˆØ¸ â†’ ÙŠÙˆÙ„Ù‘Ø¯ ÙÙˆØ±Ø§Ù‹."""
    server_name = (request.form.get("server_name") or "").strip()
    months = int(request.form.get("months") or 6)

    if not server_name:
        flash("Ø±Ø¬Ø§Ø¡Ù‹ Ø£Ø¯Ø®Ù„ÙŠ Ø§Ø³Ù… Ø§Ù„Ø³ÙŠØ±ÙØ± Ù„Ø§Ø³ØªØ¹Ø±Ø§Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬.", "error")
        return redirect(url_for("index"))

    work = server_dir_path(server_name)
    future_data_csv = work / f"future_DATA_{months}M.csv"

    # Ø¥Ù† Ù„Ù… ÙŠÙˆØ¬Ø¯ Ù…Ù„Ù Ø§Ù„ØªÙ†Ø¨Ø¤ Ù„ÙƒÙ† ÙŠÙˆØ¬Ø¯ Ù…ÙˆØ¯ÙŠÙ„ Ù…Ø­ÙÙˆØ¸ â†’ Ù†ÙˆÙ„Ù‘Ø¯ Ø³Ø±ÙŠØ¹Ø§Ù‹
    if not future_data_csv.exists():
        model_data_path = work / "model_DATA.np"
        model_log_path  = work / "model_LOG.np"
        data_csv = work / "data_preprocessed.csv"
        log_csv  = work / "log_preprocessed.csv"
        if model_data_path.exists() and model_log_path.exists() and data_csv.exists() and log_csv.exists():
            try:
                _ = forecast_only(str(model_data_path), str(data_csv), "DATA", months, out_dir=str(work))
                _ = forecast_only(str(model_log_path),  str(log_csv),  "LOG",  months, out_dir=str(work))
            except Exception as e:
                flash(f"Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ù…Ø­ÙÙˆØ¸Ø© Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¯Ø© ÙˆÙ„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† ØªÙˆÙ„ÙŠØ¯Ù‡Ø§: {e}", "error")
                return redirect(url_for("index"))
        else:
            flash("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ù…Ø­ÙÙˆØ¸Ø© Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¯Ø©. Ø´ØºÙ‘Ù„ÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø«Ù… Ø§Ù„ØªÙ†Ø¨Ø¤ Ø£ÙˆÙ„Ø§Ù‹.", "error")
            return redirect(url_for("index"))

    return _render_results_page(work, server_name, months)

def _render_results_page(work: Path, server_name: str, months: int):
   
    future_data_csv = work / f"future_DATA_{months}M.csv"
    if not future_data_csv.exists():
        flash("âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ù ØªÙ†Ø¨Ø¤ Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¯Ø©.", "error")
        return redirect(url_for("index"))

    df = pd.read_csv(future_data_csv)
    mb_col = "SizeInMB" if "SizeInMB" in df.columns else "yhat1"
    df = df[["ds", mb_col]].rename(columns={"ds": "Ø§Ù„ØªØ§Ø±ÙŠØ®", mb_col: "Ø§Ù„Ø­Ø¬Ù… (MB)"})

    # ---------------- Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ù…Ø¹ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ----------------
    try:
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù…
        df["Ø§Ù„Ø­Ø¬Ù… (MB)"] = pd.to_numeric(df["Ø§Ù„Ø­Ø¬Ù… (MB)"], errors="coerce")
        df["Ø§Ù„Ø­Ø¬Ù… (GB)"] = (df["Ø§Ù„Ø­Ø¬Ù… (MB)"] / 1024).round(2)
    except Exception as e:
        flash(f"âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù Ø§Ù„ØªÙ†Ø¨Ø¤: {str(e)}", "error")
        return redirect(url_for("index"))
    # -----------------------------------------------------------------------------------

    chart_labels = df["Ø§Ù„ØªØ§Ø±ÙŠØ®"].tolist()
    chart_values = df["Ø§Ù„Ø­Ø¬Ù… (GB)"].tolist()

    # -------- Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù…Ù† data_preprocessed.csv --------
    chart_labels_history, chart_values_history = [], []
    history_csv = work / "data_preprocessed.csv"
    if history_csv.exists():
        df_hist = pd.read_csv(history_csv)
        df_hist["ds"] = pd.to_datetime(df_hist["ds"])
        # Ù†Ø¹ØªÙ…Ø¯ Ù†ÙØ³ Ù…Ù†Ø·Ù‚Ùƒ Ø§Ù„Ø­Ø§Ù„ÙŠ Ù‚Ø¨Ù„ Ù†Ù‚Ø·Ø© Ø§Ù„Ø¨Ø¯Ø¡ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù„Ù„ØªÙ†Ø¨Ø¤
        df_hist = df_hist[df_hist["ds"] < pd.to_datetime("2025-08-01")]
        df_hist["y"] = np.expm1(df_hist["y"].clip(-50, 50))
        df_hist["GB"] = (df_hist["y"] / 1024).round(2)
        chart_labels_history = df_hist["ds"].dt.strftime("%Y-%m").tolist()
        chart_values_history = df_hist["GB"].tolist()
    # ------------------------------------------------------------------

    files = []
    for fname in [
        f"future_DATA_{months}M.csv",
        f"future_LOG_{months}M.csv",
        "test_forecast_DATA.csv",  # Ù‚Ø¯ ØªÙƒÙˆÙ† Ù…ÙˆØ¬ÙˆØ¯Ø© Ù…Ù† ØªØ¬Ø§Ø±Ø¨ Ø³Ø§Ø¨Ù‚Ø©
        "test_forecast_LOG.csv",
    ]:
        if (work / fname).exists():
            files.append(fname)

    return render_template(
        "results.html",
        server_name=server_name,
        work_rel=work.name,
        months=months,
        table=df.to_dict(orient="records"),
        files=files,
        chart_labels=chart_labels,
        chart_values=chart_values,
        chart_labels_history=chart_labels_history,
        chart_values_history=chart_values_history
    )


# -------------------- Ø£ÙƒØ«Ø± Ù…Ù† Ø³ÙŠØ±ÙØ± --------------------
@app.post("/list_servers")
def list_servers():
    if "excel_file_multi" not in request.files:
        flash("Ù„Ù… ÙŠØªÙ… Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³Ù„.", "error"); return redirect(url_for("multi_page"))
    up = request.files["excel_file_multi"]
    if up.filename == "" or not allowed_file(up.filename):
        flash("Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³Ù„ ØºÙŠØ± ØµØ§Ù„Ø­.", "error"); return redirect(url_for("multi_page"))

    token = uuid.uuid4().hex
    saved = UPLOADS_DIR / f"{token}.xlsx"
    up.save(str(saved))
    if not saved.exists():
        flash("ÙØ´Ù„ Ø­ÙØ¸ Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³Ù„.", "error"); return redirect(url_for("multi_page"))

    session["multi_excel_path"] = str(saved)

    try:
        df = pd.read_excel(str(saved))
        cols = {c.lower(): c for c in df.columns}
        server_col = cols.get("servername") or cols.get("server_name")
        if not server_col:
            flash("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ ServerName ÙÙŠ Ø§Ù„Ù…Ù„Ù.", "error")
            return redirect(url_for("multi_page"))
        names = sorted({str(x).strip() for x in df[server_col].dropna().unique() if str(x).strip()})
    except Exception as e:
        flash(f"ØªØ¹Ø°Ù‘Ø± Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {e}", "error")
        return redirect(url_for("multi_page"))

    if not names:
        flash("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø£Ø³Ù…Ø§Ø¡ Ø³ÙŠØ±ÙØ±Ø§Øª ÙÙŠ Ø§Ù„Ù…Ù„Ù.", "error")
        return redirect(url_for("multi_page"))

    return render_template("multi.html", server_list=names)

@app.post("/forecast_multi")
def forecast_multi():
    months = int(request.form.get("months") or 6)
    selected = request.form.getlist("servers")

    if not selected:
        flash("Ø±Ø¬Ø§Ø¡Ù‹ Ø§Ø®ØªØ§Ø±ÙŠ Ø³ÙŠØ±ÙØ±Ù‹Ø§ ÙˆØ§Ø­Ø¯Ù‹Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„.", "error")
        return redirect(url_for("multi_page"))

    all_server_data = {}      # Ù„Ù„ØªÙˆÙ‚Ø¹ ÙÙ‚Ø· (ÙŠØ¨Ù†ÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„)
    full_label_set = set()    # Ù„ÙƒÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® (Ù…Ø§Ø¶ÙŠ + ØªÙˆÙ‚Ø¹) â†’ Ù„Ù„Ø´Ø§Ø±Øª
    datasets = []

    green_shades = [
        "rgba(14,138,72,1)",   # Ø£Ø®Ø¶Ø± ØºØ§Ù…Ù‚
        "rgba(16,185,129,1)",  # Ø£Ø®Ø¶Ø± Ø³Ø§Ø·Ø¹
        "rgba(52,211,153,1)",  # Ø£Ø®Ø¶Ø± Ù…ØªÙˆØ³Ø·
        "rgba(110,231,183,1)", # Ø£Ø®Ø¶Ø± ÙØ§ØªØ­
    ]

    excel_path = session.get("multi_excel_path")

    # -------- ØªØ¬Ù‡ÙŠØ² Ø¨ÙŠØ§Ù†Ø§Øª ÙƒÙ„ Ø³ÙŠØ±ÙØ± --------
    for idx, name in enumerate(selected):
        try:
            work = server_dir(name)
            data_csv = work / "data_preprocessed.csv"
            log_csv  = work / "log_preprocessed.csv"

            # âœ… Ø¥Ø°Ø§ Ø§Ù„Ø³ÙŠØ±ÙØ± ØºÙŠØ± Ù…Ø­Ø¶Ø± â†’ Ø­Ø¶Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¢Ù†
            if not data_csv.exists() or not log_csv.exists():
                if excel_path and Path(excel_path).exists():
                    try:
                        _data_csv, _log_csv = run_preprocess(str(excel_path), name, out_dir=str(work))
                        data_csv, log_csv = Path(_data_csv), Path(_log_csv)
                    except Exception as e:
                        flash(f"âš ï¸ Ø§Ù„Ø³ÙŠØ±ÙØ± {name}: ÙØ´Ù„ ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ({e})", "error")
                        continue
                else:
                    flash(f"âš ï¸ Ø§Ù„Ø³ÙŠØ±ÙØ± {name}: Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ù Ø¥ÙƒØ³Ù„ ØµØ§Ù„Ø­ Ù„Ù„ØªØ­Ø¶ÙŠØ±.", "error")
                    continue

            future_file = work / f"future_DATA_{months}M.csv"
            model_data_path = work / "model_DATA.np"
            model_log_path  = work / "model_LOG.np"

            # âœ… Ø¥Ø°Ø§ Ù…Ø§ Ø¹Ù†Ø¯Ù‡ Ù…Ù„Ù ØªÙ†Ø¨Ø¤ â†’ Ù†Ø­Ø§ÙˆÙ„ Ø¥Ù†Ø´Ø§Ø¤Ù‡
            if not future_file.exists():
                try:
                    if model_data_path.exists() and model_log_path.exists():
                        _ = forecast_only(str(model_data_path), str(data_csv), "DATA", months, out_dir=str(work))
                        _ = forecast_only(str(model_log_path),  str(log_csv),  "LOG",  months, out_dir=str(work))
                    else:
                        run_full_pipeline(
                            data_csv=str(data_csv),
                            log_csv=str(log_csv),
                            params_data=str(BASE_DIR / "best_params_DATA.json"),
                            params_log=str(BASE_DIR / "best_params_LOG.json"),
                            out_dir=str(work),
                            months=months
                        )
                except Exception as e:
                    msg = str(e)
                    if "singular value" in msg.lower():
                        flash(f"âš ï¸ Ø§Ù„Ø³ÙŠØ±ÙØ± {name}: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø«Ø§Ø¨ØªØ© Ø¬Ø¯Ù‹Ø§ ÙˆÙ„Ø§ ÙŠÙ…ÙƒÙ† ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.", "error")
                    else:
                        flash(f"âš ï¸ Ø§Ù„Ø³ÙŠØ±ÙØ± {name}: ÙØ´Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ({msg[:120]}...)", "error")
                    continue

            # -------- Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ù…Ùˆ Ø§Ù„Ø³Ø§Ø¨Ù‚ --------
            hist_map = {}
            hist_path = work / "data_preprocessed.csv"
            if hist_path.exists():
                df_hist = pd.read_csv(hist_path)
                df_hist["ds"] = pd.to_datetime(df_hist["ds"])
                df_hist = df_hist[df_hist["ds"] <= pd.Timestamp("2025-07-31")]
                df_hist["y"] = np.expm1(df_hist["y"].clip(-50, 50))
                df_hist["GB"] = (df_hist["y"] / 1024).round(2)
                df_hist["label"] = df_hist["ds"].dt.strftime("%Y-%m")
                hist_map = dict(zip(df_hist["label"], df_hist["GB"]))

            # -------- Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙˆÙ‚Ø¹ --------
            if not future_file.exists():
                flash(f"âš ï¸ Ø§Ù„Ø³ÙŠØ±ÙØ± {name}: Ù„Ù… ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø§Ù„ØªÙ†Ø¨Ø¤.", "error")
                continue

            df_fut = pd.read_csv(future_file)
            df_fut["ds"] = pd.to_datetime(df_fut["ds"])
            df_fut["GB"] = (df_fut["SizeInMB"] / 1024).round(2)
            df_fut["label"] = df_fut["ds"].dt.strftime("%Y-%m")
            forecast_map = dict(zip(df_fut["label"], df_fut["GB"]))

            # -------- Ù†Ø¯Ù…Ø¬ ÙƒÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® Ù„Ù„Ø´Ø§Ø±Øª --------
            all_labels = sorted(set(hist_map.keys()) | set(forecast_map.keys()))

            # Ø®Ø· Ø§Ù„Ù†Ù…Ùˆ Ø§Ù„Ø³Ø§Ø¨Ù‚ (Ø±Ù…Ø§Ø¯ÙŠ)
            datasets.append({
                "label": f"{name} (Ø§Ù„Ù†Ù…Ùˆ Ø§Ù„Ø³Ø§Ø¨Ù‚)",
                "data": [hist_map.get(l, None) for l in all_labels],
                "fill": False,
                "borderColor": "gray",
                "borderWidth": 2,
                "pointRadius": 3,
                "tension": 0.2
            })

            # Ø®Ø· Ø§Ù„ØªÙˆÙ‚Ø¹ (Ø£Ø®Ø¶Ø±)
            color = green_shades[idx % len(green_shades)]
            datasets.append({
                "label": f"{name} (ØªÙˆÙ‚Ø¹)",
                "data": [forecast_map.get(l, None) for l in all_labels],
                "fill": False,
                "borderColor": color,
                "borderWidth": 3,
                "pointRadius": 5,
                "tension": 0.3
            })

            # ğŸ‘‡ Ø§Ù„Ø¬Ø¯ÙˆÙ„ ÙŠØ¹ØªÙ…Ø¯ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„ØªÙˆÙ‚Ø¹
            all_server_data[name] = forecast_map  
            full_label_set.update(all_labels)

        except Exception as e:
            flash(f"âš ï¸ Ø§Ù„Ø³ÙŠØ±ÙØ± {name}: Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ({str(e)[:100]}...)", "error")
            continue

    # -------- Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¬Ø¯ÙˆÙ„ (ÙÙ‚Ø· Ø§Ù„ØªÙˆÙ‚Ø¹ Ø¨Ø¹Ø¯ Ø¢Ø®Ø± ØªØ§Ø±ÙŠØ® ÙØ¹Ù„ÙŠ) --------
    if not all_server_data:
        flash("âŒ Ù„Ù… ÙŠÙ†Ø¬Ø­ Ø£ÙŠ Ø³ÙŠØ±ÙØ± ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ†Ø¨Ø¤.", "error")
        return redirect(url_for("multi_page"))

    labels_all = sorted({l for f in all_server_data.values() for l in f.keys()})

    # Ù†Ø­Ø¯Ø¯ Ø¢Ø®Ø± Ø´Ù‡Ø± ÙØ¹Ù„ÙŠ Ù…Ù† ÙƒÙ„ Ø§Ù„Ø³ÙŠØ±ÙØ±Ø§Øª
    last_hist_dates = []
    for name in all_server_data.keys():
        hist_path = server_dir(name) / "data_preprocessed.csv"
        if hist_path.exists():
            df_hist = pd.read_csv(hist_path)
            df_hist["ds"] = pd.to_datetime(df_hist["ds"])
            if not df_hist.empty:
                last_hist = df_hist["ds"].max().strftime("%Y-%m")
                last_hist_dates.append(last_hist)

    cutoff = max(last_hist_dates) if last_hist_dates else None
    labels_forecast_only = [l for l in labels_all if not cutoff or l > cutoff]

    # Ù†Ø¨Ù†ÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ù…Ù† Ø§Ù„ØªÙˆÙ‚Ø¹ ÙÙ‚Ø·
    rows, totals = [], {l: 0.0 for l in labels_forecast_only}
    for name, fdata in all_server_data.items():
        row = {"Ø§Ø³Ù… Ø§Ù„Ø³ÙŠØ±ÙØ±": name}
        for l in labels_forecast_only:
            val = fdata.get(l)
            if val is not None:
                row[l] = val
                totals[l] += val
        rows.append(row)

    total_row = {"Ø§Ø³Ù… Ø§Ù„Ø³ÙŠØ±ÙØ±": "Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹"}
    for l, val in totals.items():
        total_row[l] = round(val, 2)
    if rows:
        rows.append(total_row)

    summary_df = pd.DataFrame(rows)
    stamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    summary_work = f"_multi_{stamp}"
    out_dir = RUNS_DIR / summary_work
    out_dir.mkdir(exist_ok=True)
    summary_file = f"summary_MULTI_{months}M.csv"
    summary_df.to_csv(out_dir / summary_file, index=False, encoding="utf-8-sig")

    flash("âœ… ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù„Ù„Ø³ÙŠØ±ÙØ±Ø§Øª Ø§Ù„Ù…Ù…ÙƒÙ†Ø©. Ø§Ù„Ø³ÙŠØ±ÙØ±Ø§Øª Ø§Ù„ÙØ§Ø´Ù„Ø© ØªÙ… ØªØ¬Ø§Ù‡Ù„Ù‡Ø§.", "success")

    return render_template(
        "multi.html",
        server_list=None,
        multi_table=summary_df.to_dict(orient="records"),
        summary_work=summary_work,
        summary_file=summary_file,
        chart_labels_multi=sorted(full_label_set),  # ğŸ‘ˆ Ø§Ù„Ø´Ø§Ø±Øª = Ù…Ø§Ø¶ÙŠ + ØªÙˆÙ‚Ø¹
        chart_datasets_multi=datasets,
        months=months,
        labels_forecast_only=labels_forecast_only   # ğŸ‘ˆ Ù†Ø±Ø³Ù„ Ù„Ù„Ø¬Ø¯ÙˆÙ„ ÙÙ‚Ø·
    )

# -------------------- Ø§Ù„ØªÙ†Ø²ÙŠÙ„ --------------------
@app.get("/download/<work>/<path:fname>")
def download(work, fname):
    d = RUNS_DIR / secure_filename(work)
    return send_from_directory(d, fname, as_attachment=True)

if __name__ == "__main__":
    app.run(debug=True)
